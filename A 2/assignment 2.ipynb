{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd097a40",
   "metadata": {},
   "source": [
    "### Article Generation using N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd8420",
   "metadata": {},
   "source": [
    "You have to write the urdu article using ngrams (1 grams to 5 grams). So, in short your output must be of 5 paragraphs, the first one is generated using unigram, second one is generated using bigram and so on.\n",
    "\n",
    "Input: Your input is the seed sentence. E.g. first 3 to 4 words of the paragraph.\n",
    "\n",
    "Output: Your output is the consist of 5 paragraphs for each n gram, each of 200 words.\n",
    "\n",
    "You have to make N-gram model using the provided dataset. Dataset can be downloaded from  https://www.kaggle.com/datasets/saurabhshahane/urdu-news-dataset \n",
    "\n",
    "You have to use all News Text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb709115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adf87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_news=pd.read_excel(\"urdu-news-dataset-1M.xlsx\",nrows=15,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3fcea5",
   "metadata": {},
   "source": [
    "# Unirgam Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "523cfe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_model(a):\n",
    "    if(type(a) is not str):\n",
    "        b=' '.join(str(i)for i in a)\n",
    "        return word_tokenize(b)\n",
    "    else:\n",
    "        return word_tokenize(a)\n",
    "\n",
    "def bigram_model(a):\n",
    "    bigram=[]\n",
    "    unigram=unigram_model(a)\n",
    "    for i in range(len(unigram)):\n",
    "        if i<len(unigram)-1:\n",
    "            value=unigram[i]+\" \"+unigram[i+1]\n",
    "            value=value.split(\" \")\n",
    "            z=[i for i in value]\n",
    "            bigram.append(tuple(z))\n",
    "    return bigram\n",
    "def trigram_model(a):\n",
    "    unigram=unigram_model(a)\n",
    "    trigram=[]\n",
    "    for i in range(len(unigram)):\n",
    "        if i<len(unigram)-2:\n",
    "            value=unigram[i]+\" \"+unigram[i+1]+\" \"+unigram[i+2]\n",
    "            value=value.split(\" \")\n",
    "            z=[i for i in value]\n",
    "            trigram.append(tuple(z))\n",
    "    return trigram\n",
    "def tetragram_model(a):\n",
    "    unigram=unigram_model(a)\n",
    "    tetragram=[]\n",
    "    for i in range(len(unigram)):\n",
    "        if i<len(unigram)-3:\n",
    "            value=unigram[i]+\" \"+unigram[i+1]+\" \"+unigram[i+2]+\" \"+unigram[i+3]\n",
    "            value=value.split(\" \")\n",
    "            z=[i for i in value]\n",
    "            tetragram.append(tuple(z))\n",
    "    return tetragram\n",
    "def hexa_gram_model(a):\n",
    "    unigram=unigram_model(a)\n",
    "    hexagram=[]\n",
    "    for i in range(len(unigram)):\n",
    "        if i<len(unigram)-4:\n",
    "            value=unigram[i]+\" \"+unigram[i+1]+\" \"+unigram[i+2]+\" \"+unigram[i+3]+\" \"+unigram[i+4]\n",
    "            value=value.split(\" \")\n",
    "            z=[i for i in value]\n",
    "            hexagram.append(tuple(z))\n",
    "    return hexagram\n",
    "\n",
    "def ngram_model_construction(a,ngram_value):\n",
    "    if ngram_value==1:\n",
    "        return unigram_model(a)\n",
    "    elif ngram_value==2:\n",
    "        return bigram_model(a)\n",
    "    elif ngram_value==3:\n",
    "        return trigram_model(a)\n",
    "    elif ngram_value==4:\n",
    "        return tetragram_model(a)\n",
    "    elif ngram_value==5:\n",
    "        return hexa_gram_model(a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f260ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_sentence(word):\n",
    "    c=[]\n",
    "    b=ngram_model_construction(urdu_news[\"News Text\"],1)\n",
    "    for i in range(len(b)):\n",
    "        if b[i]==word:\n",
    "            i=i+1\n",
    "            w=[]\n",
    "            while(i<len(b) and b[i]!=word):\n",
    "                    w.append(b[i])\n",
    "                    i=i+1\n",
    "            c.append(w)\n",
    "    number=np.random.randint(0,len(c))\n",
    "    sent=\" \".join(str(i) for i in c[number])\n",
    "    return(word+\" \"+sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f9c6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_sentence(word):\n",
    "    original_word=word\n",
    "    b=ngram_model_construction(urdu_news[\"News Text\"],2)\n",
    "    new_dict={}\n",
    "    total_words=0\n",
    "    for i in b:\n",
    "        if i not in new_dict:\n",
    "            new_dict[i]=1\n",
    "            total_words=total_words+1\n",
    "        else :\n",
    "            new_dict[i]+=1\n",
    "            total_words=total_words+1\n",
    "    for i in new_dict:\n",
    "        new_dict[i]=new_dict[i]/total_words\n",
    "    word=word.split(\" \")\n",
    "    word=word[-1]\n",
    "    value=''\n",
    "    prob=0\n",
    "    answer=[]\n",
    "    for j in range(0,200):\n",
    "        for i in new_dict:\n",
    "            if word in i[0]:\n",
    "                if prob==0:\n",
    "                    value=i[1]\n",
    "                    prob=new_dict[i]\n",
    "                else:\n",
    "                    if prob<new_dict[i]:\n",
    "                        value=i[1]\n",
    "                        prob=new_dict[i]\n",
    "        answer.append(value)\n",
    "        word=value\n",
    "        prob=0\n",
    "    answer=\" \".join(str(i) for i in answer)\n",
    "    return original_word+\" \"+answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a759f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_sentence(word):\n",
    "    new_dict={}\n",
    "    b=ngram_model_construction(urdu_news[\"News Text\"],3)\n",
    "    total_words=0\n",
    "    original_word=word\n",
    "    word=word.split(\" \")\n",
    "    word=word[-1]\n",
    "    for i in b:\n",
    "        if i not in new_dict:\n",
    "            new_dict[i]=1\n",
    "            total_words=total_words+1\n",
    "        else:\n",
    "            new_dict[i]+=1\n",
    "            total_words+=1\n",
    "    for i in new_dict:\n",
    "            new_dict[i]=new_dict[i]/total_words\n",
    "    value=''\n",
    "    prob=0\n",
    "    answer=[]\n",
    "    for j in range(0,200):\n",
    "        for i in new_dict:\n",
    "            if word in i[0]:\n",
    "                if prob==0:\n",
    "                    value=i[1]\n",
    "                    prob=new_dict[i]\n",
    "                    last_value=i[2]\n",
    "                else:\n",
    "                    if prob<new_dict[i]:\n",
    "                        value=i[1]\n",
    "                        prob=new_dict[i]\n",
    "                        last_value=i[2]\n",
    "        answer.append(value)\n",
    "        word=last_value\n",
    "        prob=0\n",
    "    answer=\" \".join(str(i) for i in answer)\n",
    "    return original_word+\" \"+answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e5ec2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tetragram_sentence(word):\n",
    "    new_dict={}\n",
    "    b=ngram_model_construction(urdu_news[\"News Text\"],4)\n",
    "    total_words=0\n",
    "    original_word=word\n",
    "    word=word.split(\" \")\n",
    "    word=word[-1]\n",
    "    for i in b:\n",
    "        if i not in new_dict:\n",
    "            new_dict[i]=1\n",
    "            total_words=total_words+1\n",
    "        else:\n",
    "            new_dict[i]+=1\n",
    "            total_words+=1\n",
    "    for i in new_dict:\n",
    "            new_dict[i]=new_dict[i]/total_words\n",
    "    value=''\n",
    "    prob=0\n",
    "    answer=[]\n",
    "    for j in range(0,200):\n",
    "        for i in new_dict:\n",
    "            if word in i[0]:\n",
    "                if prob==0:\n",
    "                    value=i[1]\n",
    "                    prob=new_dict[i]\n",
    "                    last_value=i[2]\n",
    "                else:\n",
    "                    if prob<new_dict[i]:\n",
    "                        value=i[1]\n",
    "                        prob=new_dict[i]\n",
    "                        last_value=i[2]\n",
    "        answer.append(value)\n",
    "        word=last_value\n",
    "        prob=0\n",
    "    answer=\" \".join(str(i) for i in answer)\n",
    "    return original_word+\" \"+answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "845c14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexagram_sentence(word):\n",
    "    new_dict={}\n",
    "    b=ngram_model_construction(urdu_news[\"News Text\"],5)\n",
    "    total_words=0\n",
    "    original_word=word\n",
    "    word=word.split(\" \")\n",
    "    word=word[-1]\n",
    "    for i in b:\n",
    "        if i not in new_dict:\n",
    "            new_dict[i]=1\n",
    "            total_words=total_words+1\n",
    "        else:\n",
    "            new_dict[i]+=1\n",
    "            total_words+=1\n",
    "    for i in new_dict:\n",
    "            new_dict[i]=new_dict[i]/total_words\n",
    "    value=''\n",
    "    prob=0\n",
    "    answer=[]\n",
    "    for j in range(0,200):\n",
    "        for i in new_dict:\n",
    "            if word in i[0]:\n",
    "                if prob==0:\n",
    "                    value=i[1]\n",
    "                    prob=new_dict[i]\n",
    "                    last_value=i[2]\n",
    "                else:\n",
    "                    if prob<new_dict[i]:\n",
    "                        value=i[1]\n",
    "                        prob=new_dict[i]\n",
    "                        last_value=i[2]\n",
    "        answer.append(value)\n",
    "        word=last_value\n",
    "        prob=0\n",
    "    answer=\" \".join(str(i) for i in answer)\n",
    "    return original_word+\" \"+answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19f2c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_construction(word):\n",
    "    print(unigram_sentence(word),\"\\n\")\n",
    "    print(bigram_sentence(word),\"\\n\")\n",
    "    print(trigram_sentence(word),\"\\n\")\n",
    "    print(tetragram_sentence(word),\"\\n\")\n",
    "    print(hexagram_sentence(word),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151847ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79601988",
   "metadata": {},
   "source": [
    "### Classify language out of the list given below using just stop words. Remove punctuations, make it lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa286b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "output={}\n",
    "for i in stopwords.fileids():\n",
    "    output[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bdad25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=\"An article is qualunque member van un class of dedicated words naquele estÃ£o used with noun phrases per mark the identifiability of the referents of the noun phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8fb9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=list(Test.split(\" \"))\n",
    "new_test=[]\n",
    "for i in range(len(Test)):\n",
    "    Test[i]=Test[i].lower()\n",
    "    if Test[i] not in new_test:\n",
    "        new_test.append(Test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00511c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_test:\n",
    "    for j in stopwords.fileids():\n",
    "        stop=stopwords.words(j)\n",
    "        if i in stop:\n",
    "            output[j]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266654b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arabic': 0,\n",
       " 'azerbaijani': 1,\n",
       " 'basque': 0,\n",
       " 'bengali': 0,\n",
       " 'catalan': 3,\n",
       " 'chinese': 0,\n",
       " 'danish': 0,\n",
       " 'dutch': 3,\n",
       " 'english': 5,\n",
       " 'finnish': 0,\n",
       " 'french': 1,\n",
       " 'german': 1,\n",
       " 'greek': 0,\n",
       " 'hebrew': 0,\n",
       " 'hinglish': 8,\n",
       " 'hungarian': 1,\n",
       " 'indonesian': 1,\n",
       " 'italian': 2,\n",
       " 'kazakh': 0,\n",
       " 'nepali': 0,\n",
       " 'norwegian': 0,\n",
       " 'portuguese': 1,\n",
       " 'romanian': 1,\n",
       " 'russian': 0,\n",
       " 'slovene': 0,\n",
       " 'spanish': 1,\n",
       " 'swedish': 0,\n",
       " 'tajik': 0,\n",
       " 'turkish': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your output looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d15f2698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arabic': 0,\n",
       " 'azerbaijani': 1,\n",
       " 'basque': 0,\n",
       " 'bengali': 0,\n",
       " 'catalan': 3,\n",
       " 'chinese': 0,\n",
       " 'danish': 0,\n",
       " 'dutch': 3,\n",
       " 'english': 5,\n",
       " 'finnish': 0,\n",
       " 'french': 1,\n",
       " 'german': 1,\n",
       " 'greek': 0,\n",
       " 'hebrew': 0,\n",
       " 'hinglish': 8,\n",
       " 'hungarian': 1,\n",
       " 'indonesian': 1,\n",
       " 'italian': 2,\n",
       " 'kazakh': 0,\n",
       " 'nepali': 0,\n",
       " 'norwegian': 0,\n",
       " 'portuguese': 1,\n",
       " 'romanian': 1,\n",
       " 'russian': 0,\n",
       " 'slovene': 0,\n",
       " 'spanish': 1,\n",
       " 'swedish': 0,\n",
       " 'tajik': 0,\n",
       " 'turkish': 0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43708fa5",
   "metadata": {},
   "source": [
    "### Rule Based Roman Urdu Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f761e",
   "metadata": {},
   "source": [
    "Roman Urdu lacks standard lexicon and usually many spelling variations exist for a given word, e.g., the word zindagi (life) is also written as zindagee, zindagy, zaindagee and zndagi. So, in this question you have to Normalize Roman Urdu words using the following Rules given in the attached Pdf. Your Code works for a complete Sentence or multiple sentences.\n",
    "\n",
    "For Example: zaroori, zaruri, zarori map to the 'zrory'. So zrory becomes the correct word for all representations mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dd7e7159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zrory', 'zrory', 'zrory']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "normalized_list=[]\n",
    "test=\"zaroori zaruri zarori\"\n",
    "test=list(test.split(\" \"))\n",
    "for i in test:\n",
    "    value=i[-3:]\n",
    "    if value==\"ain\":\n",
    "        value=i[:-3]+'e'+i[-2:]\n",
    "    \n",
    "    value=i[1:]\n",
    "    if \"ar\" in value:\n",
    "        value=value.replace(\"ar\",\"r\")\n",
    "        i=i[0]+value\n",
    "    \n",
    "    if \"ai\" in i:\n",
    "        i=i.replace(\"ai\",\"ae\")\n",
    "    \n",
    "    if \"y\" in i:\n",
    "        i=re.sub(\"iyyyyyy|iyyyyy|iyyyy|iyyy|iyy|iy\",\"I\",i)\n",
    "    \n",
    "    if i[-2:]==\"ay\":\n",
    "        i=i[:-2]+\"e\"\n",
    "    \n",
    "    if \"h\" in i:\n",
    "        i=re.sub(\"ihhhhhh|ihhhhh|ihhhh|ihhh|ihh|ih\",\"eh\",i)\n",
    "    \n",
    "    if i[-2:]==\"ey\":\n",
    "        i=i[:-2]+\"e\"\n",
    "    \n",
    "    if \"s\" in i:\n",
    "        i=re.sub(\"sssss|ssss|sss|ss\",\"s\",i)\n",
    "    \n",
    "    if i[-2:]==\"ie\":\n",
    "        i=i[:-2]+\"y\"\n",
    "    \n",
    "    if \"ry\" in i[:-1]:\n",
    "        i=i.replace(\"ry\",\"ri\")\n",
    "    \n",
    "    if \"es\"==i[:2]:\n",
    "        i=\"is\"+i[2:]\n",
    "    \n",
    "    if \"sy\" in i[:-1]:\n",
    "        i=i.replace(\"sy\",\"si\")\n",
    "    \n",
    "    \n",
    "    if \"a\" in i:\n",
    "        i=re.sub(\"aaaaa|aaaa|aaa|aa\",\"a\",i)\n",
    "    \n",
    "    if \"ty\" in i[:-1]:\n",
    "        i=i.replace(\"ty\",\"ti\")\n",
    "    \n",
    "    if \"j\" in i:\n",
    "        i=re.sub(\"jjjjj|jjjj|jjj|jj\",\"j\",i)\n",
    "    \n",
    "    if \"o\" in i:\n",
    "         i=re.sub(\"ooooo|oooo|ooo|oo\",\"o\",i)\n",
    "    \n",
    "    if \"e\"in i:\n",
    "        i=re.sub(\"eeeeeeee|eeeeee|eeee|ee\",\"i\",i)\n",
    "    \n",
    "    if i[-1]==\"i\":\n",
    "        if i[-2]>=\"b\"and i[-2]<=\"z\":\n",
    "            i=i[:-1]+\"y\"\n",
    "            \n",
    "    if \"d\" in i:\n",
    "        i=re.sub(\"ddddd|dddd|ddd|dd\",\"d\",i)\n",
    "        \n",
    "    if \"u\"in i:\n",
    "        i=i.replace(\"u\",\"o\")\n",
    "   \n",
    "    normalized_list.append(i)\n",
    "normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "843a8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value=i[1:]\n",
    "# if \"ar\" in value:\n",
    "#     value=value.replace(\"ar\",\"r\")\n",
    "#     i=i[0]+value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "142c871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=\"zaraibaoai\"\n",
    "# if \"ai\" in i:\n",
    "#     i=i.replace(\"ai\",\"ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2aa2315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IazImI'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"iyyaziyyymiyyyyy\"\n",
    "# if \"y\" in i:\n",
    "#     i=re.sub(\"iyyyyyy|iyyyyy|iyyyy|iyyy|iyy|iy\",\"I\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc1c9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee2f1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=\"zaray\"\n",
    "# if i[-2:]==\"ay\":\n",
    "#     i=i[:-2]+\"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "272481f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ehazehmeh'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"ihhazihhhmihhhhh\"\n",
    "# if \"h\" in i:\n",
    "#     i=re.sub(\"ihhhhhh|ihhhhh|ihhhh|ihhh|ihh|ih\",\"eh\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c4ab230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=\"zarey\"\n",
    "# if i[-2:]==\"ey\":\n",
    "#     i=i[:-2]+\"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b1d502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saas'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"ssssaasss\"\n",
    "# if \"s\" in i:\n",
    "#     i=re.sub(\"sssss|ssss|sss|ss\",\"s\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6d1987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zary'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zarie\"\n",
    "# if i[-2:]==\"ie\":\n",
    "#     i=i[:-2]+\"y\"\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c964770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zaria'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zarya\"\n",
    "# if \"ry\" in i[:-1]:\n",
    "#     i=i.replace(\"ry\",\"ri\")\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d63077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isah'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"esah\"\n",
    "# if \"es\"==i[:2]:\n",
    "#     i=\"is\"+i[2:]\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83bbad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zsia'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zsya\"\n",
    "# if \"sy\" in i[:-1]:\n",
    "#     i=i.replace(\"sy\",\"si\")\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77db263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zara'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zaaaraa\"\n",
    "# if \"a\" in i:\n",
    "#     i=re.sub(\"aaaaa|aaaa|aaa|aa\",\"a\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b06a93f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ztia'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"ztya\"\n",
    "# if \"ty\" in i[:-1]:\n",
    "#     i=i.replace(\"ty\",\"ti\")\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d8657bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zjrj'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zjjjrjjjj\"\n",
    "# if \"j\" in i:\n",
    "#     i=re.sub(\"jjjjj|jjjj|jjj|jj\",\"j\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3faa25dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zoro'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"zoooroo\"\n",
    "# if \"o\" in i:\n",
    "#     i=re.sub(\"ooooo|oooo|ooo|oo\",\"o\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1b080505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iziaie'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"eezeeeeaeee\"\n",
    "# if \"e\"in i:\n",
    "#     i=re.sub(\"eeeeeeee|eeeeee|eeee|ee\",\"i\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b90d5f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcai'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"abcai\"\n",
    "# if i[-1]==\"i\":\n",
    "#     if i[-2]>=\"b\"and i[-2]<=\"z\":\n",
    "#         i=i[:-1]+\"y\"\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b2e42122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dahdidi'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"ddahdidi\"\n",
    "# if \"d\" in i:\n",
    "#     i=re.sub(\"ddddd|dddd|ddd|dd\",\"d\",i)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e766341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aooziha'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"aouziha\"\n",
    "# if \"u\"in i:\n",
    "#     i=i.replace(\"u\",\"o\")\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9dcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "266e06d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "c2634d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "f401830f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d1e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419348b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11243d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6aadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca872901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cc163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2d4b550c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "695574af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092b649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
